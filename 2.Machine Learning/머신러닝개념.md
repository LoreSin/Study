# 머신러닝개념
    대표적으로 AlphaGo, 자율주행 자동차
    AI 소피아(검색 해보기)

## ML 분류
    AI(인공지능) > ML(머신러닝) > Deep Learning (딥러닝)
    딥러닝은 머신러닝 분야중 하나

## 머신러닝  분류

- Supervised learning ★
    + 답(Label) 이 있는 데이터로 학습.
- Unsupervised learning
    + Label 이 아닌 유사도로 대상을 구분
- Reinforcement learning


## 머신러닝 사용례

- 이미지 라벨추가
- 이메일 스팸필터
- 시험점수 추측.


## Supervised learning 의 분야
- Regression (선형 예측)
    + 점수를 예측
- 2진 분류 (양자 예측)
    + 성공(True) / 실패(False) 
- 다중 답 분류 (다자 예측)
    - 등급 분리 (A,B,C,D . . 등)


#### Linear Regression : 선형회귀 : 2진 예측
    y = ax+b 로 정의되는 직선으로 예측.

-Cost Functions (Loss Functions)
    오류를 최소화 하는 방법
    GDA : Gradient Descent Algorithm

#### GDA (Cost Functions)
    W에 대한 Cost 는 cost(W) 으로 표현.
    α : 학습률 (Learning Rate)
    W := W - α * [d/dW] * cost(W)
    # 기존 W 값을 cost(W) 의 미분값에 α비율 만큼 빼서 갱신

#### Convex Function
    Hypothesis => Cost function => GDA 으로 최저점을 찾을때 나오는 함수
    3D 표현상으로 그릇모양처럼 나오는 함수라는 의미.


#### 단일변수 vs 다중변수
    단일변수의 예측 : Y = Wx + b
    다중변수의 예측 : Y = W1x1 + W2x2 + W3x3 + b

    H(X) = XW 를 매트릭스로 표현
    [x1,x2,x3] * [[W1],[W2],[W3]] = [Y]
    1*3행렬  *   3*1 행렬  = 1*1 행렬
    n*3행렬  *   3*1 행렬  = n*1 행렬

#### 분류 상 선형회귀의 문제 => 로지스틱 회귀
    애매한 경우 or 극단케이스에 의해 정상적인 데이터들을 제대로 분류 할수 없거나 제대로 학습되지 않음. .
    로지스틱 회귀 : 선형회귀의 오류를 발생하는 요소를 감안한 회귀방법. 
    
- Sigmoid : 각 요소를 특정한 곡선으로 출력이 나옴.
    표준분포상의 일부로 존재한다고 가정하는것. (e : 자연상수 를 이용한 식.)

- 회귀방법 간  차이
    + **선형회귀** : 추측식을 직선 (WX+b),  cost 는 LSM 등으로 사용
    + **로지스틱 회귀** : 시그모이드방식을 이용한 방법. 
        + 추측식 = 1 / 1 + e^(-WX)
        * 이것에 맞는 별도의 cost 필요.
        * cost(W) = 1/m Σ c(H(x), y)
        * c(H(x), y) 는 y = 1 일때 -log(H(x))
        * c(H(x), y) 는 y = 0 일때 -log(1-H(x))
        * 이를 정리하면
        * c(H(x), y) = - ylog(H(x)) - (1-y)log(1-H(x))




## Sigmoid
    hypothesis 로 나온 추측값을 0 ~ 1 사이로 정규화 하는 함수

## MultiNormial Classification (다중 분류 추측)
    Sigmoid 함수를 이용한 각 분류별 확률을 구하는 Hypothesis
    cost Function : Cross Entropy Erorr

- Sigmoid 를 이용한 추측 : 각 추측들이 어느정도의 확률인가를 구하는 방법
- Cross Entropy : Σn=i(각 i실제값 - 각 i추측값)
    + 모두 합쳐서


## Overfit
    훈련셋에 과적합되어 학습데이터 이외의 자료를 추측하기 어려움.
    테스트셋과 훈련데이터간의 정확도가 많이 차이나는 현상.

#### Overfit 해법들
1. 트레이닝데이터 증가
2. 피처모델을 줄인다.
3. 정규화 (Regulation)


## NN : Neural Nerwork
퍼셉트론을 여러개의 층을 이용해, XOR 과 같은 문제를 해결한 방법

## Activation
    hypthesis 를 적절한 값으로 출력하는것.
    대표적으로 SIGMOID 를 썻지만. . . 

#### Sigmoid 의 문제
    Sigmoid 를 이용한 추측이, NN 의 층이 깊어질수록 제대로 된 추측을 하지 못하는 현상
    곱연산으로 인한, Vanishing Gradient 가 이유
    이로 인해 20년간 (1986~2006) 인공지능이 빛을 보지 못함 (인공지능 겨울?)

- Vanishing Gradient : 곱연산으로 인해, 층이 깊어지면 멀리 있는 층(출력층 기준, 입력층에 가까울수록) 의 W 수치가 매우 낮아짐. 즉, 입력과 출력의 연관성이 사라진 현상.
- 이후, RELU 함수 (REctified Linear Unit)로 개선함.
    0.5 이하는 0, 0.5 이상은 입력값 그대로


#### DNN 과 WEIGHT
    초기화 방법에서 weight 값은 잘 줘야 학습이 잘된다
    그래서 그러한 방법이 중요해짐

RBM 방법 : 이전에 주로 사용된 WEIGHT 초기값 사용법
Xavier 방법 


#### CNN : 부분적 구역의 특징을 이용한 학습방법
    Convolusion Layer 을 이용한 방법
    Conv Layer + Pooling Layer
    AlexNet (이미지 대회에서 나온 대표적인 방법)


## SVM : Support Vector Machine 
    하나의 선으로 데이터값을 분리 하는 것. : 양쪽의 데이터군을 정확히 분리하는 벡터

- 분리 원칙
    + 값들의 분류가 우선
    + 최대의 간격을 지향
- 예외가 생기면? : 가능한 최선의 벡터 선택
- 비 선형 SVM : 한 점에서 뭉친경우
    + 특징을 추가하여, 선으로 나눔. (ex Z=x^2 + y^2)

- Kernel Trick : 변수의 요소를 여러개를 사용
    + X1, Y => X1~~ Xn 개.
    + 비 선형적 문제에서 사용

- 파라매터들
    + Kernel (linear, rbf, poly, ...), C, Gamma
    + C : 곡선의 값을 결정
    + Gamma : 마진거리를 계산시, 적용할 데이터의 종류
        * Low value : 먼 것
        * High value : 가까운 것 
- Overfitting
    + 값을 지나치게 반영해서, 최적의 선을 만들어가지 못한 불규칙한 곡선이나 구부러진 선으로 답을 맞추는 형태로 형성.


## HOG (Histogram of Oriented Gradients)
    지역밝기 (국소범위의 밝은정도의 변화율) 를 벡터화

사진의 경우, 픽셀방향의 차이값(x, y) 을 삼각함수로 벡터값을 계산
이, **벡터방향** (θ:각도) 들을 **히스토그램**에 **벡터값**으로 추가.

CELL = 지역크기의 단위. (8pixel * 8pixel 등)
bin 단위에 따라 n*n 개
Block = CELL 의 모음. (2cell * 2cell 등)

HOG => Linear SVM 을 사용하여 훈련, 사람을 검출가능.


## 객체 검출
    DATASET =>
    HOG, MCT 로 feature 추출 =>
    분류(Adaboost, random forest) 를 통해 보행자 검출하는 모델 생성 (PD MODEL)

    실제 영상을 피라미드이미지 (1/N 배 된 축소이미지모음) 에 feature 적용

    PD MODEL 과 feature 피라미드이미지를 이용해 위치를 검출하여 표현.



- NMS: Non maximum suppression
    + 하나의 대상에서 중복으로 검출된 데이터들을 하나로 취급하는 방법
    + Bitwise 연산을 통해, 비슷한 위치에 겹쳐진 경우, 하나의 대상으로 간주
    + 히트맵 방식으로 어떤 위치가 하나의 방식으로 가능
    + 가장 적합한 검출데이터 ROI 나 영역을 합친 ROI 을 사용.  (대상이나 경우에 따라 적용.)


## 차량 검출 (VD)
    학습 : haarlike, HOG 등의 피처링 - SVM 학습으로 모델생성. ACC, FP, FN 등으로 확인.
    추측 : 원본영상 => 영상을 피라미드영상으로 모델을 가지고, 부위별 확인.
        특정 부위가 두드러지면 (다수회 검출) NMS 등의 방법으로 유사하게 검출된 것을 하나로 간주.



||Positive|Nagative|
|---|---:|---:|
|True|맞춘참 TP |맞춘거짓 TN|
|False|틀린 참 FP |틀린 거짓 FN |

>**FP, FN** 과 정확도를 기준으로 모델을 평가.


## 이미지의 거리산출
    칼리브레이션 - Focal length 를 이용해, 해당과의 거리비로 측정.
    Focal Length 및 소실점을 이용해 해당의 높이 + 기준길이를 비교해 산출
    
#### Visual Odemetry
    영상의 고정물체를 이용한, 자기위치 (카메라 기준) 을 이용해 이동경로를 추측한 방법
    주변 정적 환경에서 이동경로 및 소실점등을 정적대상의 위치를 추정하기 쉽다.
    카메라의 소실점을 찾는 알고리즘 + 이동경로를 구현. 

#### 스테레오 카메라
    Disparity : 카메라 양쪽 영상 간의 동일객체의 거리차이
    각 물체의 거리기준에 대한 Disparity






